#!/usr/bin/env python3
"""
Quick start ottimizzato per RunPod H200
Risolve automaticamente il problema 0% GPU usage
"""

import torch
import os
from training.trainer import create_trainer

def main():
    print("ğŸš€ H200 Training Setup")
    print("=" * 50)
    
    # ğŸ”¥ H200 SPECIFIC CHECKS
    if not torch.cuda.is_available():
        print("âŒ CUDA non disponibile!")
        return
        
    gpu_name = torch.cuda.get_device_name(0)
    print(f"ğŸ¯ GPU Detected: {gpu_name}")
    
    # H200 detection
    is_h200 = "H200" in gpu_name.upper()
    if is_h200:
        print("ğŸš€ H200 DETECTED - Applying optimizations!")
    
    # ğŸ”¥ CONFIGURAZIONE OTTIMIZZATA PER H200
    config = {
        "input_dir": "Starlossno-1/starmodel dataset/input",
        "starless_dir": "Starlossno-1/starmodel dataset/starless", 
        "output_dir": "outputs",
        "experiment_name": "h200_optimized" if is_h200 else "gpu_training",
        "batch_size": 24 if is_h200 else 16,  # H200 puÃ² gestire batch piÃ¹ grandi
        "image_size": (512, 512),
        "num_workers": 16,  # SarÃ  ottimizzato automaticamente
        "device": "cuda"
    }
    
    print(f"ğŸ“Š Training Configuration:")
    for k, v in config.items():
        print(f"  {k}: {v}")
    print("=" * 50)
    
    # Crea trainer (con tutte le ottimizzazioni H200 giÃ  integrate)
    trainer = create_trainer(**config)
    
    # Avvia training
    trainer.train(num_epochs=100, save_every=5)
    
    print("âœ… Training completato!")

if __name__ == "__main__":
    main()
